{
    "model": {
        "vocab_size": 10000,
        "embed_size": 256,
        "hidden_size": 512,
        "num_layers": 4,
        "num_heads": 8,
        "dropout": 0.5
    },
    "training": {
        "lr": 0.0001,
        "batch_size": 128,
        "max_sequence_length": 50,
        "num_epochs": 10,
        "stop_loss": 0.0006
    },
    "generation": {
        "num_tokens": 100,
        "temperature": 0.7
    }
}
